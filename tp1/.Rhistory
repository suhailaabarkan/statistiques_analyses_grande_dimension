head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
pred_test <- knn(Xtrain, Xtest, Ytrain, 31)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
pred_test <- knn(Xtrain, Xtest, Ytrain, 31)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(123)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(123)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(123)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
pred_test <- knn(Xtrain, Xtest, Ytrain, 31)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 37+0 données test sont mal prédites
set.seed(123)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(2)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
set.seed(123)
pred_test <- knn(Xtrain, Xtest, Ytrain, 30)
head(pred_test) # les 5 premiers points sont affectés à la classe 2
table(pred_test,Ytest) # 36+0 données test sont mal prédites
train <- read.table(file="synth_train.txt", header=TRUE)
Xtrain <- train[,-1]
Ytrain <- train$y
plot(Xtrain, pch=Ytrain, col=Ytrain)
legend("topleft", legend=c("classe1", "classe2"), pch=1:2, col=1:2)
n <- nrow(train)
n1 <- sum(train$y==1)
n2 <- sum(train$y==2)
pi_1 <- n1 / n
pi_2 <- n2 / n
mu_1 <- colMeans(train[train$y == 1, c("x1", "x2")])
mu_2 <- colMeans(train[train$y == 2, c("x1", "x2")])
sigma_1 <- cov(train[train$y == 1, c("x1", "x2")])
sigma_2 <- cov(train[train$y == 2, c("x1", "x2")])
list(pi_1=pi_1, mu_1=mu_1, sigma_1=sigma_1, pi_2=pi_2, mu_2=mu_2, sigma_2=sigma_2)
Q <- function(x, pi, mu, sigma) {
- 1/2 * log(det(sigma)) - 1/2 * t(x - mu) %*% solve(sigma) %*% (x - mu) + log(pi)
}
x_new <- c(-1, 1)
Q1_x <- Q(x_new, pi_1, mu_1, sigma_1)
Q2_x <- Q(x_new, pi_2, mu_2, sigma_2)
cat("Q1(x) =", Q1_x, "\n")
cat("Q2(x) =", Q2_x, "\n")
if (Q1_x > Q2_x) {
cat("La donnée est affectée à la classe 1\n")
} else {
cat("La donnée est affectée à la classe 2\n")
}
P1 <- exp(Q1_x) / (exp(Q1_x) + exp(Q2_x))
P2 <- exp(Q2_x) / (exp(Q1_x) + exp(Q2_x))
cat("P1 =", P1, "\n")
cat("P2 =", P2, "\n")
cat("P1 + P2 =", P1 + P2, "\n")
library(MASS)
qda_model <- qda(Xtrain, as.factor(Ytrain))
x_new_df <- data.frame(x1 = -1, x2 = 1)
prediction <- predict(qda_model, x_new_df)
cat("La classe prédite est la classe :", prediction$class, "\n")
cat("avec probabilités :", prediction$posterior)
#on peut utiliser grid.rda au lieu de créer x1_vals et x2_vals
x1_vals <- seq(min(Xtrain$x1), max(Xtrain$x1), length.out = 100)
x2_vals <- seq(min(Xtrain$x2), max(Xtrain$x2), length.out = 100)
grid <- expand.grid(x1 = x1_vals, x2 = x2_vals)
grid_pred <- predict(qda_model, grid)$class
plot(grid, pch = 20, col = grid_pred, cex = 0.5,
main = "Frontière de décision de la méthode qda")
points(Xtrain, pch = Ytrain, col = Ytrain)
legend("topleft", legend = c("classe 1", "classe 2"), pch = 1:2, col = 1:2, bg="white")
#Classe 1
n<-nrow(Xtrain)
ind<-which(Ytrain==1)
mu_1<-colMeans(Xtrain[ind,])
sigma_1<-var(Xtrain[ind,])
pi_1<-nrow(ind)/n
#Classe 2
ind2<-which(Ytrain==2)
mu_2<-colMeans(Xtrain[ind2,])
sigma_2<-var(Xtrain[ind2,])
pi_2<-nrow(ind2)/n
sigma <- (1/n)*((n1*sigma_1)+(n2*sigma_2))
sigma
L <- function(x, pi, mu, sigma) {
t(x)%*%solve(sigma)%*%mu - 1/2 * t(mu)%*%solve(sigma)%*%mu + log(pi)
}
x_new <- c(-1, 1)
L1_x <- L(x_new, pi_1, mu_1,sigma)
L2_x <- L(x_new, pi_2, mu_2,sigma)
cat("L1(x) =", L1_x, "\n")
cat("L2(x) =", L2_x, "\n")
if (L1_x > L2_x) {
cat("La donnée est affectée à la classe 1\n")
} else {
cat("La donnée est affectée à la classe 2\n")
}
data <- read.table("numbers_train.txt", header=TRUE)
Xtrain <- as.matrix(data[,-1])
Ytrain <- as.factor(data[,1])
par(mfrow=c(3,3))
for (i in 1:9){
image(matrix(Xtrain[i,],16,16), col=gray(1:100/100), ylim=c(1,0)) }
library(MASS)
Y_factor<-as.factor(Ytrain)
lda_model <- lda(x = Xtrain, grouping = Y_factor)
#lda_model
prediction <- predict(lda_model, Xtrain)
prediction$class
err_app <- sum(prediction$class!=Ytrain)/length(Ytrain)
err_app
test <- read.table("numbers_test.txt", header=TRUE)
Xtest <- as.matrix(test[,-1])
Ytest <- as.factor(test[,1])
library(MASS)
Y_factor<-as.factor(Ytrain)
lda_model <- lda(x = Xtrain, grouping = Y_factor)
#lda_model
prediction <- predict(lda_model, Xtest)
prediction$class
err_test <- sum(prediction$class!=Ytest)/length(Ytest)
err_test
g<-qda(Xtrain,as.factor(Ytrain))
table(Ytrain)
X<-rbind(Xtrain,Xtest)
Y <- c(Ytrain,Ytest)
pred<-Y
for (i in 1:nrow(X)){
g <- lda(X[-i,], Y[-i])
pred[i] <- predict(g,X[i,,drop=FALSE])$class
}
X<-rbind(Xtrain,Xtest)
Y <- c(Ytrain,Ytest)
pred<-Y
lda_model_LOO <- lda(X, Y, CV=TRUE)
err_loo <- sum(lda_model_LOO$class != Y) / length(Y)
err_loo
for (i in 1:nrow(X)){
g <- lda(X[-i,], Y[-i])
pred[i] <- predict(g,X[i,,drop=FALSE])$class
}
sum(pred!=Y)/length(Y)
adq_estim <- function(X, Y) {
classes <- unique(Y)
K <- length(classes)
pi_k <- numeric(K)
mu_k <- list()
sigma_k <- list()
for (k in 1:K) {
indices <- which(Y == classes[k])
pi_k[k] <- length(indices) / length(Y)
mu_k[[k]] <- colMeans(X[indices, ])
sigma_k[[k]] <- cov(X[indices, ])
}
return(list(pi_k = pi_k, mu_k = mu_k, sigma_k = sigma_k))
}
train <- read.table(file="synth_train.txt", header=TRUE)
Xtrain <- train[,-1]
Ytrain <- train$y
adq_estim(Xtrain,Ytrain)
adq_pred <- function(params, X_new) {
pi_k <- params$pi_k
mu_k <- params$mu_k
sigma_k <- params$sigma_k
K <- length(pi_k)
prob_post <- matrix(0, nrow = nrow(X_new), ncol = K)
for (k in 1:K) {
prob_post[, k] <- pi_k[k] * mvtnorm::dmvnorm(X_new, mean = mu_k[[k]], sigma = sigma_k[[k]])
}
prob_post <- prob_post / rowSums(prob_post)
predictions <- apply(prob_post, 1, which.max)
return(list(predictions = predictions, prob_post = prob_post))
}
adq_estim <- function(X, Y) {
K <- length(unique(Y)) # Nombre de classes
n <- nrow(X)           # Nombre d'observations
p <- ncol(X)           # Nombre de variables
pi_k <- numeric(K)     # Proportions des classes
mu_k <- matrix(0, K, p) # Moyennes des classes
Sigma_k <- vector("list", K) # Listes de matrices de covariance
for (k in 1:K) {
indices_k <- which(Y == k)
n_k <- length(indices_k)
# Estimation des paramètres pour chaque classe k
pi_k[k] <- n_k / n                    # Estimation de pi_k
mu_k[k, ] <- colMeans(X[indices_k, ]) # Estimation de mu_k
Sigma_k[[k]] <- cov(X[indices_k, ])   # Estimation de Sigma_k
}
return(list(pi_k = pi_k, mu_k = mu_k, Sigma_k = Sigma_k))
}
train <- read.table(file="synth_train.txt", header=TRUE)
Xtrain <- train[,-1]
Ytrain <- train$y
adq_estim(Xtrain,Ytrain)
X_new<-c(-1,1)
params<-adq_estim(Xtrain,Ytrain)
adq(params,X_new)
X_new<-c(-1,1)
params<-adq_estim(Xtrain,Ytrain)
adq_pred(params,X_new)
X_new <- matrix(c(-1, 1), nrow = 1)
params<-adq_estim(Xtrain,Ytrain)
adq_pred(params,X_new)
X_new <- data.frame(x1=-1,x2=1)
params<-adq_estim(Xtrain,Ytrain)
adq_pred(params,X_new)
setwd("/Users/mathildetissandier/Documents/GitHub/statistiques_analyses_grande_dimension/tp1")
load("prostate.RData")
n<-nrow(prostate)
p<-8
X <- as.matrix(prostate[,1:8])
Y <- prostate[,9]
# Charger les données
load("malbouffe.RData")
data[,2:7]<-apply(data[,2:7],2,as.factor) # variables qualitatives
data<-DataExplorer::update_columns(data, c(1,8:11), as.numeric)
summary(data)
model_complet <- lm(formula = malbouffe ~ ., data = data)
step.b.AIC <- step(model_complet, direction = "backward", data = data)
summary(step.b.AIC)
fullmodel <- lm(malbouffe ~ ., data = data)
step.b.pvalue <- SignifReg(fit = fullmodel, scope = list(lower = ~1, upper = fullmodel), alpha = 0.05, direction = "backward", criterion = "p-value", adjust.method = "none", trace = FALSE)
# Charger les données
load("malbouffe.RData")
data[,2:7]<-apply(data[,2:7],2,as.factor) # variables qualitatives
data<-DataExplorer::update_columns(data, c(1,8:11), as.numeric)
summary(data)
library(MASS)
library(SignifReg)
library(leaps)
library(gtools)
model_complet <- lm(formula = malbouffe ~ ., data = data)
step.b.AIC <- step(model_complet, direction = "backward", data = data)
summary(step.b.AIC)
fullmodel <- lm(malbouffe ~ ., data = data)
step.b.pvalue <- SignifReg(fit = fullmodel, scope = list(lower = ~1, upper = fullmodel), alpha = 0.05, direction = "backward", criterion = "p-value", adjust.method = "none", trace = FALSE)
summary(step.b.pvalue)
model_vide <- lm(formula = malbouffe ~ 1, data = data)
step.f.AIC <- stepAIC(model_vide, scope = list(upper = model_complet, lower = model_vide), direction = "forward", data = data)
summary(step.f.AIC)
nullmodel <- lm(malbouffe ~ 1, data = data)
step.f.pvalue <- SignifReg(fit = nullmodel, scope = list(upper = fullmodel, lower = nullmodel), alpha = 0.05, direction = "forward", criterion = "p-value", adjust.method = "none", trace = FALSE)
summary(step.f.pvalue)
#Convertir les variables qualitatives en numériques :
#utiliser la fonction model.matrix() pour transformer automatiquement les facteurs en variables indicatrices (dummy variables)
# Nombre d'observations
n <- dim(data)[1]
# Séparer les variables explicatives (x) et la variable réponse (y)
x <- data[, -which(colnames(data) == "malbouffe")]
y <- as.matrix(data[,"malbouffe"], nrow=n)
colnames(y) <- colnames(data)[colnames(data) == "malbouffe"]
p <- dim(x)[2]
# Fonction pour concaténer des chaînes
"%+%" <- function(x, y) paste(x, y, sep="")
# Générer tous les sous-ensembles de variables
models <- cbind(combinations(p, 1, 1:p), array(0, dim = c(p, p-1)))
for (i in 2:p) {
nc <- dim(combinations(p, i, 1:p))[1]
models <- rbind(models, cbind(combinations(p, i, 1:p), array(0, dim = c(nc, p-i))))
}
# Nombre de folds pour la cross-validation
folds <- 10
all.folds <- split(sample(1:n), rep(1:folds, length = n))
error <- matrix(NA, ncol = 1, nrow = folds)
errorCV <- matrix(NA, ncol = 1, nrow = dim(models)[1])
# Boucle sur tous les sous-ensembles possibles de variables
for (i in 1:dim(models)[1]){
variables <- models[i, which(models[i,] > 0)]
X <- x[, variables]  # Sélection des colonnes correspondantes
# Gestion du cas où il n'y a qu'une seule variable
if (length(variables) == 1){
X <- as.data.frame(X)
colnames(X) <- colnames(x)[variables]
}
# Utilisation de model.matrix pour transformer les variables qualitatives en dummies
X_full <- model.matrix(~ ., data = as.data.frame(X))[,-1]  # Supprimer l'intercept
# Transformer X_full en matrice si nécessaire (pour éviter les erreurs)
if (is.null(dim(X_full))) {
X_full <- matrix(X_full, ncol = 1)
}
model_i <- as.formula(paste("malbouffe ~", paste(colnames(X), collapse = "+")))
for (j in seq(folds)){
#**********
# Estimation
#**********
omit <- all.folds[[j]]
# Apprentissage du modèle sur les données d'entraînement (sans les observations omises)
beta <- lm(model_i, data = data[-omit,])$coefficients
#**********
# Test
#**********
# Appliquer les mêmes transformations sur les données de test (omises)
X_test <- as.matrix(X_full[omit,])  # Transformation des variables qualitatives en matrice
if (is.null(dim(X_test))) {
X_test <- matrix(X_test, ncol = 1)  # Assurer que X_test reste une matrice
}
# Calcul des prédictions
Y_hat <- beta[1] + X_test %*% beta[-1]
# Calcul de l'erreur
error[j] <- t(Y_hat - y[omit,]) %*% (Y_hat - y[omit,]) / length(omit)
}
# Calcul de l'erreur moyenne sur tous les folds
errorCV[i] <- mean(error)
}
# Afficher le modèle qui minimise l'erreur de validation croisée
best_model <- models[which.min(errorCV), ]
colnames(x)[best_model]
# Packages nécessaires
library(combinat)  # Pour générer les combinaisons
n <- dim(data)[1] # Nombre d'observations
x <- data[, -which(colnames(data) == "malbouffe")]  # Variables explicatives
y <- data[,"malbouffe"]  # Variable dépendante
p <- dim(x)[2]  # Nombre de variables explicatives
# Génération des combinaisons de modèles
models <- list()
for (i in 1:p) {
models[[i]] <- combinations(p, i, 1:p)  # Tous les sous-ensembles de taille i
}
# Fonction pour calculer l'AIC pour chaque sous-ensemble de variables
get_AIC <- function(variables, data) {
X <- data[, variables]
if (length(variables) <= 1) {
X <- as.matrix(X)
colnames(X) <- colnames(data)[variables]
}
# Construction du modèle et calcul de l'AIC
model_formula <- as.formula(paste("malbouffe ~", paste(colnames(X), collapse = "+")))
fit <- lm(model_formula, data = data)
return(AIC(fit))
}
# Liste pour stocker les AIC et les modèles
results <- data.frame(AIC = numeric(), Model = character())
# Boucle sur toutes les combinaisons possibles de variables
for (i in 1:p) {
for (j in 1:nrow(models[[i]])) {
variables <- models[[i]][j, ]
# Calcul de l'AIC pour ce sous-ensemble de variables
current_AIC <- get_AIC(variables, data)
# Sauvegarde du résultat
results <- rbind(results, data.frame(AIC = current_AIC,
Model = paste(colnames(x)[variables], collapse = "+")))
}
}
# Trouver le modèle avec l'AIC minimum
best_model <- results[which.min(results$AIC), ]
print(best_model)
load("malbouffe.RData")
names(data)
str(data)
DataExplorer::plot_intro(data)
library(MASS)
library(SignifReg)
library(leaps)
library(gtools)
#-------------------------
#Transformation en factor:
#-------------------------
data[,2:7]<-apply(data[,2:7],2,as.factor) # variables qualitatives
#-------------------------
#Transformation en numeric:
#-------------------------
data<-DataExplorer::update_columns(data, c(1,8:11), as.numeric)
summary(data)
model_complet <- lm(formula = malbouffe ~ ., data = data)
step.b.AIC <- step(model_complet, direction = "backward", data = data)
summary(step.b.AIC)
fullmodel <- lm(malbouffe ~ ., data = data)
step.b.pvalue <- SignifReg(fit = fullmodel, scope = list(lower = ~1, upper = fullmodel), alpha = 0.05, direction = "backward", criterion = "p-value", adjust.method = "none", trace = FALSE)
summary(step.b.pvalue)
model_vide <- lm(formula = malbouffe ~ 1, data = data)
step.f.AIC <- stepAIC(model_vide, scope = list(upper = model_complet, lower = model_vide), direction = "forward", data = data)
summary(step.f.AIC)
nullmodel <- lm(malbouffe ~ 1, data = data)
step.f.pvalue <- SignifReg(fit = nullmodel, scope = list(upper = fullmodel, lower = nullmodel), alpha = 0.05, direction = "forward", criterion = "p-value", adjust.method = "none", trace = FALSE)
summary(step.f.pvalue)
# Nombre d'observations
n <- dim(data)[1]
# Séparer les variables explicatives (x) et la variable réponse (y)
x <- data[, -which(colnames(data) == "malbouffe")]
y <- as.matrix(data[,"malbouffe"], nrow=n)
colnames(y) <- colnames(data)[colnames(data) == "malbouffe"]
p <- dim(x)[2]
# Fonction pour concaténer des chaînes
"%+%" <- function(x, y) paste(x, y, sep="")
# Générer tous les sous-ensembles de variables
models <- cbind(combinations(p, 1, 1:p), array(0, dim = c(p, p-1)))
for (i in 2:p) {
nc <- dim(combinations(p, i, 1:p))[1]
models <- rbind(models, cbind(combinations(p, i, 1:p), array(0, dim = c(nc, p-i))))
}
# Nombre de folds pour la cross-validation
folds <- 10
all.folds <- split(sample(1:n), rep(1:folds, length = n))
error <- matrix(NA, ncol = 1, nrow = folds)
errorCV <- matrix(NA, ncol = 1, nrow = dim(models)[1])
# Boucle sur tous les sous-ensembles possibles de variables
for (i in 1:dim(models)[1]){
variables <- models[i, which(models[i,] > 0)]
X <- x[, variables]  # Sélection des colonnes correspondantes
# Gestion du cas où il n'y a qu'une seule variable
if (length(variables) == 1){
X <- as.data.frame(X)
colnames(X) <- colnames(x)[variables]
}
# Utilisation de model.matrix pour transformer les variables qualitatives en dummies
X_full <- model.matrix(~ ., data = as.data.frame(X))[,-1]  # Supprimer l'intercept
# Transformer X_full en matrice si nécessaire (pour éviter les erreurs)
if (is.null(dim(X_full))) {
X_full <- matrix(X_full, ncol = 1)
}
model_i <- as.formula(paste("malbouffe ~", paste(colnames(X), collapse = "+")))
for (j in seq(folds)){
#**********
# Estimation
#**********
omit <- all.folds[[j]]
# Apprentissage du modèle sur les données d'entraînement (sans les observations omises)
beta <- lm(model_i, data = data[-omit,])$coefficients
#**********
# Test
#**********
# Appliquer les mêmes transformations sur les données de test (omises)
X_test <- as.matrix(X_full[omit,])  # Transformation des variables qualitatives en matrice
if (is.null(dim(X_test))) {
X_test <- matrix(X_test, ncol = 1)  # Assurer que X_test reste une matrice
}
# Calcul des prédictions
Y_hat <- beta[1] + X_test %*% beta[-1]
# Calcul de l'erreur
error[j] <- t(Y_hat - y[omit,]) %*% (Y_hat - y[omit,]) / length(omit)
}
# Calcul de l'erreur moyenne sur tous les folds
errorCV[i] <- mean(error)
}
# Afficher le modèle qui minimise l'erreur de validation croisée
best_model <- models[which.min(errorCV), ]
colnames(x)[best_model]
# Packages nécessaires
library(combinat)  # Pour générer les combinaisons
n <- dim(data)[1] # Nombre d'observations
x <- data[, -which(colnames(data) == "malbouffe")]  # Variables explicatives
y <- data[,"malbouffe"]  # Variable dépendante
p <- dim(x)[2]  # Nombre de variables explicatives
# Génération des combinaisons de modèles
models <- list()
for (i in 1:p) {
models[[i]] <- combinations(p, i, 1:p)  # Tous les sous-ensembles de taille i
}
# Fonction pour calculer l'AIC pour chaque sous-ensemble de variables
get_AIC <- function(variables, data) {
X <- data[, variables]
if (length(variables) <= 1) {
X <- as.matrix(X)
colnames(X) <- colnames(data)[variables]
}
# Construction du modèle et calcul de l'AIC
model_formula <- as.formula(paste("malbouffe ~", paste(colnames(X), collapse = "+")))
fit <- lm(model_formula, data = data)
return(AIC(fit))
}
# Liste pour stocker les AIC et les modèles
results <- data.frame(AIC = numeric(), Model = character())
# Boucle sur toutes les combinaisons possibles de variables
for (i in 1:p) {
for (j in 1:nrow(models[[i]])) {
variables <- models[[i]][j, ]
# Calcul de l'AIC pour ce sous-ensemble de variables
current_AIC <- get_AIC(variables, data)
# Sauvegarde du résultat
results <- rbind(results, data.frame(AIC = current_AIC,
Model = paste(colnames(x)[variables], collapse = "+")))
}
}
# Trouver le modèle avec l'AIC minimum
best_model <- results[which.min(results$AIC), ]
print(best_model)
